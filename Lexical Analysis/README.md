
# Lexical Analysis

In computer science, lexical analysis, lexing or tokenization is the process of converting a sequence of characters into a sequence of lexical tokens
. It is first step of compiler 



## Deployment

Go to this folder and open cmd in this folder path
Then run this command:

```bash
  ./run.sh
```

